---
layout: post
title:  "Pictorial Bayes"
date:   2023-05-17
categories: talk
done: false
---

These slides contain the content of a talk, titled "Drawing pictures with Nico", that I gave for the Statistics Discussion Group at the Faculty of Bioscience Engineering at UGent. I have reworked parts of the talk and elaborated on many concepts. Moreover, I have added an optional part at the end which puts everything within a much more abstract setting and a teaser for the keen reader.

<hr>

The structure of the talk was as follows:
1. Short introduction on <i>probability theory</i>,
1. Diagrammatic methods for <i>Markov categories</i>,
1. <i>Rigidity</i> for finite sets,
1. Contexts as <i>categories</i>, and
1. Geometric ideas for higher mathematics.

<hr>

In most (applied) courses on probability theory and statistics, the definition of a probability distribution is given for either the case of finite sets or Euclidean spaces, without explicitly referencing the underlying structure. Moreover, many subtleties and possible problems are ignored.

The first part of the talk consisted of a formal treatment by first considering the notion of event, and only then, introducing the collection of distributions compatible with these events.

For an arbitrary set $\mathcal{X}$, a good choice of events, called <b>measurable subsets</b>, is given by the following notion.

<b>Definition ($\sigma$-algebra).</b> A collection $\Sigma\subseteq2^\mathcal{X}$ of subsets such that:
1. The set itself is measurable: $\mathcal{X}\in\Sigma$.
1. Complements of measurable sets are measurable: \\[A\in\Sigma\implies A^c\in\Sigma\,.\\]
3. Countable (disjoint) unions of measurable sets are measurable: \\[(A_n)\_{n\in\mathbb{N}}\subseteq\Sigma\implies\bigsqcup\_{i=1}^{+\infty}A\_i\in\Sigma\,.\\]

There exist two trivial examples:
* The trivial $\sigma$-algebra: $\Sigma_\text{trivial}:=\{\emptyset,\mathcal{X}\}$, and
* The discrete $\sigma$-algebra: $\Sigma_\text{disc}:=2^\mathcal{X}$.

The latter is, for example, the one used in the definition of discrete distributions. Note that these collections can be defined on any set, they do not use any structure on $\mathcal{X}$.<br><br>

<div class = "note">
When $\mathcal{X}$ comes equipped with a <i>topology</i>, i.e. a notion of <i>open sets</i>, the <b>Borel $\sigma$-algebra</b> is the smallest $\sigma$-algebra such that all open sets are measurable.
<br><br>

<div markdown="1">

* The Borel algebra on $\mathbb{R}$ is generated by the open intervals $]a,b[$ for all $a,b\in\mathbb{R}$. This is the common choice on all Euclidean spaces $\mathbb{R}^n$ and is often implicitly assumed.
* The trivial and discrete $\sigma$-algebras are induced by (and coincide with) the <i>trivial</i> and <i>discrete topologies</i>, respectively.

</div>
</div><br>

<div class = "def" text = "Probability measure">
A nonnegative set function $\mu:\Sigma\rightarrow[0,1]$ on a <b>measurable space</b> $(\mathcal{X},\Sigma)$ satisfying:

<div markdown = "1">

1. Totality: \\[\mu(\mathcal{X})=1\,.\\]
1. $\sigma$-additivity: \\[\mu\left(\bigsqcup_{i=1}^{+\infty}A_i\right)=\sum_{i=1}^{+\infty}\mu(A_i)\,.\\]

</div>

If the totality condition is relaxed, the definition of a <b>measure</b> is obtained.
</div>

An important probability measure for this talk is the <b>Dirac measure</b>:

$$
    \delta_x(A) := \mathbb{1}_A(x) =
    \begin{cases}
        0&x\not\in A\,,\\
        1&x\in A\,.
    \end{cases}
$$

A measure that can be defined on any measurable space is the <b>counting measure</b>:

$$\mu_\text{count}(A) := |A|\,.$$

As with most mathematical structures, one likes to consider functions that preserve the given structure.
<div class = "def" text = "Measurable function">
A function $f:(\mathcal{X},\Sigma_\mathcal{X})\rightarrow(\mathcal{Y},\Sigma_\mathcal{Y})$ between measurable spaces such that:

$$A\in\Sigma_\mathcal{Y}\implies f^{-1}(A)\in\Sigma_\mathcal{X}\,.$$
    
The reason for using the preimage has to do with the definition of events. Disjoint unions are not preserved under (direct) images.
</div>

Given the definition of measurable functions, (probability) measures can be transported between sets. The <b>pushforward</b> of $\mu$ along $f:(\mathcal{X},\Sigma_\mathcal{X})\rightarrow(\mathcal{Y},\Sigma_\mathcal{Y})$ is defined as

$$f_\ast\mu(A):=\mu\left(f^{-1}(A)\right)\,.$$

<div class = "note">
    Equip the set of probability measures $\mathbb{P}(\mathcal{X})$ with the measurable structure <i>generated</i> by the evaluation functionals
    
    $$\mathrm{ev}_A:\mathbb{P}(\mathcal{X})\rightarrow\mathbb{R}:P\mapsto P(A)$$
    
    for all events $A\in\Sigma$. Since every measurable function $f:(\mathcal{X},\Sigma_\mathcal{X})\rightarrow(\mathcal{Y},\Sigma_\mathcal{Y})$ sends probability measures to probability measures:

    $$f_*:\mathbb{P}(\mathcal{X})\rightarrow\mathbb{P}(\mathcal{Y}):P\mapsto P\circ f^{-1}\,,$$

    the operation $\mathbb{P}$ sending measurable spaces to sets of probability measures and functions to pushforwards obtains the structure of a <i>monad</i>, the <b>Giry monad</b>.
</div>

<br>

<div class = "def" text = "Markov kernel">
    Consider two measurable spaces $(\mathcal{X},\Sigma_\mathcal{X})$ and $(\mathcal{Y},\Sigma_\mathcal{Y})$. A <b>Markov kernel</b> $\mathcal{X}\rightarrow\mathcal{Y}$ is a function $f:\Sigma_\mathcal{Y}\times\mathcal{X}\rightarrow[0,1]$ such that:

<div markdown = "1">

1. For every $A\in\Sigma_\mathcal{Y}$: $x\mapsto f(A\mid x)$ is measurable.
1. For every $x\in\mathcal{X}$: $A\mapsto f(A\mid x)$ is a probability measure.

</div>
    
    More concisely, a Markov kernel is a measurable function $\mathcal{X}\rightarrow\mathbb{P}(\mathcal{Y})$. If the second condition is relaxed to only requiring $f(\cdot\mid x)$ to be a measure, the notion of a <b>transition kernel</b> is obtained.
</div>

Some examples of kernels are:
1. Random walk: $p(i\mid j) := p\delta_{i,j+1} + (1-p)\delta_{i,j-1}$
<!-- \begin{center}\includegraphics[width = .6\linewidth]{Figures/RandomWalk.pdf}\end{center}\pause -->
1. Identity function: $\mathbb{1}(i\mid j) := \delta_{i,j}$
<!-- \begin{center}\includegraphics[width = .3\linewidth]{Figures/Identity.pdf}\end{center}\pause -->
1. Measurable function: $f(i\mid j) := \delta_{i,f(j)}$
<!-- \begin{center}\includegraphics[width = .3\linewidth]{Figures/Measurable.pdf}\end{center} -->

Integration (against a probability measure) will not be introduced in detail (even though it was necessary for this talk). Suffice it to say that it reduces to summation in the case of point masses (and discrete distributions) and to ordinary (Riemann) integrals in the case of density functions.

<hr>